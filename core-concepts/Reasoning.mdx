Reasoning is about giving the LLM some time to think before providing the final answer.


We use standard JSON Schema with a custom annotation for LLM data extraction:

- **`X-ReasoningPrompt`** - Creates auxiliary reasoning fields to help LLMs provide context and justification for extracted values in complex scenarios.

Our promptify method optimizes schema directives for better performance while preserving the original schema structure and field definitions.


## Reasoning Prompt

A `X-ReasoningPrompt` tag in the schema generates a reasoning field alongside the data field. This is particularly useful for calculations, unit conversions, or multi-step logic.

**Example: Temperature Unit Conversion**

Let's say we have a temperature report in Celsius, but our data model expects the temperature in Fahrenheit:

```json
{
  "properties": {
    "date": {
      "format": "date",
      "title": "Date",
      "type": "string"
    },
    "location": {
      "title": "Location",
      "type": "string"
    },
    "temperature": {
      "X-ReasoningPrompt": "If the temperature is given in Celsius, make the explicit computation to convert it to Fahrenheit. If the temperature is given in Fahrenheit, leave it as is.",
      "description": "temperature in Fahrenheit",
      "title": "Temperature",
      "type": "number"
    },
    "humidity": {
      "title": "Humidity",
      "type": "number"
    },
    "conditions": {
      "title": "Conditions",
      "type": "string"
    }
  },
  "required": [
    "date",
    "location", 
    "temperature",
    "humidity",
    "conditions"
  ],
  "title": "TemperatureReport",
  "type": "object"
}
```

Without reasoning, the LLM might incorrectly use 22.5°F instead of converting from Celsius. With reasoning, it produces:

```json
{
  "date": "2024-01-15",
  "location": "New York",
  "reasoning___temperature": "The temperature is given as 22.5°C. To convert to Fahrenheit: F = (C × 9/5) + 32. So: F = (22.5 × 9/5) + 32 = 72.5°F",
  "temperature": 72.5,
  "humidity": 65,
  "conditions": "Partly Cloudy"
}
```

As you can see, the "reasoning___" fields help the LLM show its work while the final output follows your schema structure.

## Python's Pydantic BaseModel Support

You can define the custom annotations in the `pydantic.Field` class using the `json_schema_extra` field.

Here is a minimalistic example with everything you should need:

```python
from pydantic import BaseModel, Field
from datetime import date

class TemperatureReport(BaseModel):
    date: date
    location: str
    temperature: float = Field(...,
        description="temperature in Fahrenheit",
        json_schema_extra={
            "X-ReasoningPrompt": "If the temperature is given in Celsius, make the explicit computation to convert it to Fahrenheit. If the temperature is given in Fahrenheit, leave it as is.",
        }
    )
    humidity: float
    conditions: str
```

If you need a json_schema, you can convert the BaseModel to model_json_schema:

<CodeGroup>
```python main.py
TemperatureReport.model_json_schema()
```
```json result.json
{
  "properties": {
    "date": {
      "format": "date",
      "title": "Date",
      "type": "string"
    },
    "location": {
      "title": "Location",
      "type": "string"
    },
    "temperature": {
      "X-ReasoningPrompt": "If the temperature is given in Celsius, make the explicit computation to convert it to Fahrenheit. If the temperature is given in Fahrenheit, leave it as is.",
      "description": "temperature in Fahrenheit",
      "title": "Temperature",
      "type": "number"
    },
    "humidity": {
      "title": "Humidity",
      "type": "number"
    },
    "conditions": {
      "title": "Conditions",
      "type": "string"
    }
  },
  "required": [
    "date",
    "location",
    "temperature",
    "humidity",
    "conditions"
  ],
  "title": "TemperatureReport",
  "type": "object"
}
```
</CodeGroup>

---

## Complete Example

You will need to use retab's `Schema` object to leverage the directives in the schema.
<CodeGroup>
```python Pydantic
from retab import Retab, Schema
from openai import OpenAI
from pydantic import BaseModel, Field
from datetime import date

reclient = Retab()
doc_msg = reclient.documents.create_messages(
    document = "temperature_report.md"
)

class TemperatureReport(BaseModel):
    date: date
    location: str
    temperature: float = Field(...,
        description="temperature in Fahrenheit",
        json_schema_extra={
            'X-ReasoningPrompt': 'If the temperature is given in Celsius, make the explicit computation to convert it to Fahrenheit. If the temperature is given in Fahrenheit, leave it as is.',
        }
    )
    humidity: float
    conditions: str

schema_obj = Schema(
    pydantic_model = TemperatureReport
)

# Now you can use your favorite model to analyze your document
client = OpenAI()
completion = client.beta.chat.completions.parse(
    model="gpt-4o",
    messages=schema_obj.openai_messages + doc_msg.openai_messages,
    response_format=schema_obj.response_format_pydantic
)

# Validate the response against the original schema if you want to remove the reasoning fields
from retab.utils.json_schema import filter_auxiliary_fields_json
assert completion.choices[0].message.content is not None
extraction = schema_obj.pydantic_model.model_validate(
    filter_auxiliary_fields_json(completion.choices[0].message.content, schema_obj.pydantic_model)
)

print("Extraction:",extraction)
```
```python JSON Schema
from retab import Retab, Schema
from openai import OpenAI

reclient = Retab()
doc_msg = reclient.documents.create_messages(
    document = "temperature_report.md"
)
schema_obj = Schema(
    json_schema = {
        'properties': {
            'date': {
                'format': 'date',
                'title': 'Date',
                'type': 'string'
            },
            'location': {
                'title': 'Location',
                'type': 'string'
            },
            'temperature': {
                'X-ReasoningPrompt': 'If the temperature is given in Celsius, make the explicit computation to convert it to Fahrenheit. If the temperature is given in Fahrenheit, leave it as is.',
                'description': 'temperature in Fahrenheit',
                'title': 'Temperature',
                'type': 'number'
            },
            'humidity': {
                'title': 'Humidity',
                'type': 'number'
            },
            'conditions': {
                'title': 'Conditions',
                'type': 'string'
            }
        },
        'required': ['date', 'location', 'temperature', 'humidity', 'conditions'],
        'title': 'TemperatureReport',
        'type': 'object'
    }
)

# Now you can use your favorite model to analyze your document
client = OpenAI()
completion = client.chat.completions.create(
    model="gpt-4o", 
    messages=schema_obj.openai_messages + doc_msg.openai_messages,
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": schema_obj.id,
            "schema": schema_obj.inference_json_schema,
            "strict": True
        }
    }
)

# Validate the response against the original schema if you want to remove the reasoning fields
from retab.utils.json_schema import filter_auxiliary_fields_json
assert completion.choices[0].message.content is not None
extraction = schema_obj.pydantic_model.model_validate(
    filter_auxiliary_fields_json(completion.choices[0].message.content, schema_obj.pydantic_model)
)

print("Result:",extraction)
```
```python Retab Client
from retab import Retab

reclient = Retab()

# You can also use our all-in-one API
# We return a standard OpenAI response
response = reclient.documents.extract(
    document = "temperature_report.md", 
    model="gpt-4.1-nano",
    json_schema = {
      'properties': {
          'date': {
              'format': 'date',
              'title': 'Date',
              'type': 'string'
          },
          'location': {
              'title': 'Location',
              'type': 'string'
          },
          'temperature': {
              'X-ReasoningPrompt': 'If the temperature is given in Celsius, make the explicit computation to convert it to Fahrenheit. If the temperature is given in Fahrenheit, leave it as is.',
              'description': 'temperature in Fahrenheit',
              'title': 'Temperature',
              'type': 'number'
          },
          'humidity': {
              'title': 'Humidity',
              'type': 'number'
          },
          'conditions': {
              'title': 'Conditions',
              'type': 'string'
          }
      },
      'required': ['date', 'location', 'temperature', 'humidity', 'conditions'],
      'title': 'TemperatureReport',
      'type': 'object'
  },
   modality="text"
)

print(response.choices[0].message.content)
```
</CodeGroup>

---


## Key Benefits

1. **Accuracy**: LLMs perform calculations more reliably when they can show their work
2. **Transparency**: You can see exactly how the LLM arrived at its answer
3. **Debugging**: Easy to identify where conversions or calculations went wrong
4. **Trust**: Users can verify the logic behind complex transformations

## Best Practices

- Use reasoning fields for any calculations, unit conversions, or multi-step logic
- Make the reasoning description specific to guide the LLM's thought process
- Place reasoning fields before the fields that depend on the reasoning
- Keep reasoning concise but complete enough to follow the logic


## Go further

- [Schema](https://docs.retab.com/core-concepts/Schema)
- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)