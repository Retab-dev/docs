## Introduction

We use the standard JSON Schema format to organize all the directives needed to prompt an LLM for data extraction. The schema includes three custom annotations that provide additional context and guidance for large language models (LLMs):

- **`X-SystemPrompt`**  
  A top-level directive that provides general instructions or context for the LLM, ensuring consistent behavior and improving the relevance of its responses during the data extraction process.

- **`X-LLMDescription`**  
  An optional annotation that replaces or complements the `description` field for a property. It offers the LLM a more detailed understanding of the field, improving its ability to parse or interpret the data accurately.

- **`X-ReasoningDescription`**  
  This annotation creates an auxiliary field for generating reasoning or explanatory context about a property. It allows the LLM to provide additional insights or justifications for extracted values, which can be helpful in complex or ambiguous scenarios.

These annotations help ensure structured and precise interactions with LLMs while remaining compatible with standard JSON Schema conventions. 

Our prompt optimization tool (soon to be released) can analyze and refine the directives provided in the schema, such as the X-SystemPrompt and X-LLMDescription, to improve overall performance and response quality. Importantly, this optimization process leaves the extraction parameters, such as the schema’s structure and field definitions, unchanged to ensure consistency in data processing.

The following sections detail the supported data types, best practices for schema design, and implementation examples, including integration with Python’s Pydantic library.

## Supported Types

The following types are supported:

- **String**
- **Number**
- **Boolean**
- **Integer**
- **Object**
- **Array**
- **Enum**
- **anyOf**

The `anyOf` key is only supported for nullable fields. To assign a field as nullable, you can use the following example:

### Good Example

```json
{
  "type": "object",
  "properties": {
    "exampleField": {
      "anyOf": [
        { "type": "string" },
        { "type": "null" }
      ]
    }
  },
  "required": ["exampleField"]
}
```

### Bad Example

```json
{
  "type": "object",
  "properties": {
    "exampleField": {
      "anyOf": [
        { "type": "string" },
        { "type": "number" }
      ]
    }
  },
  "required": ["exampleField"]
}
```

This example is problematic because it allows multiple conflicting types without clear validation logic.

## Custom Annotations for Inference

For enhanced precision, we support three special custom annotations in the JSON schema:

1. **`X-SystemPrompt`**: The system prompt that will be sent to the underlying LLM.
2. **`X-LLMDescription`**: If present, it replaces the current property description with a more detailed one, helping the LLM better understand the property and extract it accurately.
3. **`X-ReasoningDescription`**: For fields that are harder to extract, this annotation generates a sibling field of type `string` to act as a reasoning sandbox. This helps the LLM provide better outputs since it is a language-based model.

### Examples of `X-ReasoningDescription`

This annotation can be tricky if not properly understood, so here’s a complete example:

```json
{
  "$defs": {
    "ArrayItem": {
      "X-ReasoningDescription": "This is the Array Item reasoning description",
      "properties": {
        "array_item_string_field": {
          "X-ReasoningDescription": "This is the array_item_string_field reasoning description",
          "description": "array_item_string_field description",
          "title": "Array Item String Field",
          "type": "string"
        }
      },
      "required": ["array_item_string_field"],
      "title": "ArrayItem",
      "type": "object"
    },
    "SimpleObject": {
      "properties": {
        "object_integer_field": {
          "description": "object_integer_field description",
          "title": "Object Integer Field",
          "type": "integer"
        },
        "object_string_field": {
          "X-ReasoningDescription": "This is the object_string_field reasoning description",
          "description": "object_string_field description",
          "title": "Object String Field",
          "type": "string"
        }
      },
      "required": ["object_integer_field", "object_string_field"],
      "title": "SimpleObject",
      "type": "object"
    }
  },
  "X-ReasoningDescription": "This is the root reasoning description",
  "X-SystemPrompt": "This is the system prompt",
  "properties": {
    "my_string_field": {
      "X-ReasoningDescription": "This is the my_string_field reasoning description",
      "description": "my_string_field description",
      "title": "My String Field",
      "type": "string"
    },
    "my_simple_object": {
      "$ref": "#/$defs/SimpleObject",
      "X-ReasoningDescription": "This is the my_simple_object reasoning description",
      "description": "my_simple_object description"
    },
    "my_array": {
      "X-ReasoningDescription": "This is my_array reasoning description",
      "description": "This is my_array description",
      "items": {
        "$ref": "#/$defs/ArrayItem"
      },
      "title": "My Array",
      "type": "array"
    }
  },
  "required": ["my_string_field", "my_simple_object", "my_array"],
  "title": "BasicBaseModel",
  "type": "object"
}
```

### Example Output

This schema should validate objects like this:

```json
{
  "my_string_field": "Example string value.",
  "my_simple_object": {
    "object_integer_field": 42,
    "object_string_field": "Example string in object."
  },
  "my_array": [
    {
      "array_item_string_field": "Example string in array item."
    }
  ]
}
```

However, the LLM might produce additional reasoning fields for better extraction, such as:

```json
{
  "reasoning___root": "Root reasoning context.",
  "reasoning___my_string_field": "Reasoning for my_string_field.",
  "my_string_field": "Example string value.",
  "reasoning___my_simple_object": "Reasoning for my_simple_object.",
  "my_simple_object": {
    "object_integer_field": 42,
    "reasoning___object_string_field": "Reasoning for object_string_field.",
    "object_string_field": "Example string in object."
  },
  "reasoning___my_array": "Reasoning for my_array.",
  "my_array": [
    {
      "reasoning___array_item_string_field": "Reasoning for array_item_string_field.",
      "array_item_string_field": "Example string in array item."
    }
  ]
}
```

As you can see, apart from the "reasoning___" fields, the LLM output follows the same structure as your supplied schema.

## Python's Pydantic BaseModel Support

The conversion of Pydantic's BaseModel to model_json_schema is straightforward:

```python
# your BaseModel instantiation ...

YourBaseModel.model_json_schema()
```

However, to properly access the custom annotations, you may need to set the `json_schema_extra` within the `pydantic.Field` class.

Here is a minimalistic example with everything you should need:

### Minimalistic Example

```python
import json
from pydantic import BaseModel, Field

# Main Data model
class BasicBaseModel(BaseModel):
    # Add a json_schema_extra to the root
    class Config:
        json_schema_extra = {
            "X-SystemPrompt": "This is the system prompt",
            "X-ReasoningDescription": "This is the root reasoning description"
        }

    class SimpleObject(BaseModel):
        object_integer_field: int = Field(..., description="Simple integer field description",
                                          json_schema_extra={"X-LLMDescription": "This is the object integer field LLM description"})
        object_string_field: str = Field(...,
                                         description="Simple string field description",
                                         json_schema_extra={"X-ReasoningDescription": "This is the object string field reasoning description"})

    class ArrayItem(BaseModel):
        class Config:
            json_schema_extra = {"X-ReasoningDescription": "This is the Array Item reasoning description"}
        
        array_item_string_field: str = Field(..., description="Array Item String Field description")

    my_string_field: str = Field(..., description="My String Field description")
    my_simple_object: SimpleObject = Field(..., description="Simple object description")
    my_array: list[ArrayItem] = Field(...,
                                      description="This is the array description",
                                      json_schema_extra={"X-ReasoningDescription": "This is the array reasoning description"}
                                      )
if __name__ == "__main__":
    with open("path_to_file.json", "w") as f:
        json.dump(BasicBaseModel.model_json_schema(), f, indent=4)
```

The content of `path_to_file.json` is actually the schema from [Examples of X-ReasoningDescription](#examples-of-x-reasoningdescription).


---

## Prompt Engineering Guide

This guide is designed to help you generate consistent, high-quality structured outputs using JSON schemas with custom annotations for LLMs. By combining effective prompt engineering strategies, custom annotations, and clear schema design, you can significantly improve the performance of large language models (LLMs) in structured data extraction.

---

### Overview of Core Techniques

1. **Crafting a Robust System Prompt**  
   Use the `X-SystemPrompt` annotation to define a high-level directive that sets the context, tone, and constraints for the LLM. This ensures consistent behavior and high-quality responses.
   
2. **Providing Field-Specific Guidance**  
   Use the `X-LLMDescription` annotation for detailed descriptions of each field. This complements or replaces the standard `description` field, enabling the LLM to better understand the requirements for each data point.

3. **Enabling LLM Reasoning**  
   The `X-ReasoningDescription` annotation provides the LLM with dedicated "thinking space" in the form of auxiliary fields. By giving the LLM a place to document its analysis and reasoning process before making final decisions, this annotation naturally encourages more thorough consideration of complex scenarios. The LLM can work through ambiguities, validate its interpretations, and explain its extraction choices - ultimately leading to more accurate and reliable outputs. This structured approach to reasoning is particularly valuable for fields requiring nuanced interpretation or where multiple data points need to be synthesized.

---

### Best Practices for Schema Design

#### General Guidelines
- Use **clear and concise titles** for all properties.  
- Use the **`required` field** to explicitly mark mandatory properties.  
- For **nullable fields**, use `anyOf` with `null` and the expected data type.

#### Custom Annotations
- **`X-SystemPrompt`:** Include overarching instructions for the task, such as expected tone, formatting, or extraction rules.
- **`X-LLMDescription`:** Provide detailed context for fields requiring nuanced interpretation. Example:  
  ```json
  {
    "type": "string",
    "X-LLMDescription": "The name of the client as it appears on the official invoice."
  }
  ```
- **`X-ReasoningDescription`:** Use this for fields where reasoning or additional context can clarify ambiguity. Example:  
  ```json
  {
    "type": "string",
    "X-ReasoningDescription": "Explain how the extracted name matches the format required by the client's database."
  }
  ```

---

### Implementing the Three Key Strategies

#### 1. A Good System Prompt (`X-SystemPrompt`)
The system prompt defines the LLM's overall behavior and is critical for consistent output. Example:
```json
{
  "X-SystemPrompt": "You are an expert data extraction assistant. Extract information based on the schema provided and ensure strict adherence to the JSON format."
}
```

Key tips for crafting system prompts:
- Include a **persona** (e.g., "You are a meticulous data extractor").
- Specify the **output format** (e.g., "Return only valid JSON objects").
- Define any **validation rules** (e.g., "All required fields must be populated").

---

#### 2. Field-Specific Instructions (`X-LLMDescription`)
For each property in the schema, provide field-specific instructions to ensure accurate extraction:
```json
{
  "type": "object",
  "properties": {
    "invoice_number": {
      "type": "string",
      "X-LLMDescription": "The unique identifier for the invoice, typically alphanumeric."
    },
    "date_issued": {
      "type": "string",
      "X-LLMDescription": "The date when the invoice was issued, in YYYY-MM-DD format."
    }
  },
  "required": ["invoice_number", "date_issued"]
}
```

---

#### 3. Giving the Model Time to Think (`X-ReasoningDescription`)
Encourage the model to reason before providing a final answer:
```json
{
  "type": "object",
  "properties": {
    "client_name": {
      "type": "string",
      "X-ReasoningDescription": "Provide reasoning for how this name matches the provided document."
    },
    "amount_due": {
      "type": "number",
      "X-ReasoningDescription": "Explain how the amount was calculated based on the invoice details."
    }
  }
}
```

Instruct the LLM to generate intermediate reasoning fields:
```json
{
  "reasoning___client_name": "The name matches the header on page 1 of the document.",
  "client_name": "Acme Corporation"
}
```

---

### Practical Examples

#### Simple Schema with Annotations
```json
{
  "X-SystemPrompt": "Extract invoice details as per the schema. Ensure accurate data and provide reasoning where necessary.",
  "type": "object",
  "properties": {
    "invoice_number": {
      "type": "string",
      "X-LLMDescription": "Unique invoice identifier."
    },
    "date_issued": {
      "type": "string",
      "X-ReasoningDescription": "Explain how the date was identified in the document."
    }
  },
  "required": ["invoice_number", "date_issued"]
}
```

Expected Output:
```json
{
  "reasoning___date_issued": "The date '2024-01-01' was found in the header of the document.",
  "invoice_number": "INV-12345",
  "date_issued": "2024-01-01"
}
```

---

#### Using Python with Pydantic for Schema Generation
```python
from pydantic import BaseModel, Field

class InvoiceSchema(BaseModel):
    invoice_number: str = Field(..., description="Unique identifier for the invoice",
                                json_schema_extra={"X-LLMDescription": "Unique invoice identifier."})
    date_issued: str = Field(..., description="Date in YYYY-MM-DD format",
                             json_schema_extra={"X-ReasoningDescription": "Explain how the date was identified in the document."})

    class Config:
        json_schema_extra = {
            "X-SystemPrompt": "Extract invoice details strictly following the schema."
        }

print(InvoiceSchema.schema_json(indent=4))
```

---

#### Testing and Evaluation

1. **Simulate Real-world Inputs:** Test with documents containing varying levels of complexity and ambiguity.  
2. **Evaluate Outputs Systematically:** Use criteria such as field accuracy, reasoning clarity, and JSON validity.  
3. **Iterate and Optimize:** Continuously refine prompts and schema annotations based on evaluation results.

---

### Conclusion

By leveraging **`X-SystemPrompt`**, **`X-LLMDescription`**, and **`X-ReasoningDescription`**, you can significantly enhance structured data extraction tasks. This guide provides a foundational framework to integrate these strategies into your workflows effectively.

---

### Go further

- [The JSON Schema](https://docs.uiform.com/get-started/the-json-schema)
- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)